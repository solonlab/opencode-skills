#!/usr/bin/env python3
"""
è§†é¢‘å›¾æ–‡è¯­éŸ³å¯¹é½æ ¡éªŒå™¨

åœ¨åˆæˆè§†é¢‘ä¹‹å‰ï¼Œå¿…é¡»è¿è¡Œæ­¤è„šæœ¬æ ¡éªŒï¼š
1. æ¯å¼ å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. duration æ˜¯å¦ä¸ºç²¾ç¡®æ•°å€¼ï¼ˆå¿…é¡»ä» narration.json è®¡ç®—ï¼‰
3. å›¾ç‰‡æ€»æ—¶é•¿ vs éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆè¯¯å·® < 1sï¼‰
4. æ¯å¼ å›¾æ—¶é•¿æ˜¯å¦åœ¨åˆç†èŒƒå›´ï¼ˆ1-7sï¼‰
5. å›¾ç‰‡æ–‡ä»¶åå…³é”®è¯ vs è¯­éŸ³å†…å®¹å…³é”®è¯ è¯­ä¹‰äº¤å‰æ¯”å¯¹
6. è¾“å‡ºå®Œæ•´å¯¹ç…§è¡¨

ç”¨æ³•:
    python verify_alignment.py video_config.yaml

é€€å‡ºç :
    0 = æ ¡éªŒé€šè¿‡
    1 = æ ¡éªŒå¤±è´¥ï¼Œç¦æ­¢åˆæˆ
"""
import json
import re
import sys
import yaml
from pathlib import Path


def get_audio_duration(audio_path):
    """ç”¨ ffprobe è·å–éŸ³é¢‘æ—¶é•¿"""
    import subprocess
    result = subprocess.run([
        'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
        '-of', 'csv=p=0', str(audio_path)
    ], capture_output=True, text=True)
    return float(result.stdout.strip())


def load_narration_timestamps(work_dir, audio_path):
    """åŠ è½½ narration.json æ—¶é—´æˆ³"""
    candidates = [
        work_dir / 'narration.json',
        Path(audio_path).with_suffix('.json'),
        work_dir / (Path(audio_path).stem + '.json'),
    ]
    for p in candidates:
        if p.exists():
            with open(p, 'r') as f:
                return json.load(f)
    return None


# â”€â”€ è¯­ä¹‰å…³é”®è¯æ˜ å°„è¡¨ â”€â”€
# å›¾ç‰‡æ–‡ä»¶åä¸­çš„å…³é”®è¯ â†’ è¯­éŸ³ä¸­åº”è¯¥å‡ºç°çš„å…³é”®è¯
KEYWORD_MAP = {
    # æ¨¡å‹å
    'ds': ['deepseek', 'ds', 'æ·±åº¦æ±‚ç´¢'],
    'deepseek': ['deepseek', 'ds', 'æ·±åº¦æ±‚ç´¢'],
    'glm': ['glm', 'æ™ºè°±', 'zhipu'],
    'opus': ['opus', 'claude', 'anthropic'],
    'claude': ['opus', 'claude', 'anthropic'],
    'codex': ['codex', 'openai', 'gpt'],
    'gpt': ['codex', 'openai', 'gpt'],
    'kimi': ['kimi', 'æœˆä¹‹æš—é¢', 'moonshot', 'k2'],
    'qwen': ['qwen', 'é€šä¹‰', 'é˜¿é‡Œ', 'åƒé—®'],
    'minimax': ['minimax', 'mm'],
    'mm': ['minimax', 'mm', 'minimax'],
    # åŠŸèƒ½/æ¦‚å¿µ
    'swarm': ['swarm', 'èœ‚ç¾¤', 'å¹¶è¡Œ', 'å­ä»»åŠ¡'],
    'bench': [],  # bench å¤ªé€šç”¨ï¼Œè¯­éŸ³é‡Œå¯èƒ½è¯´"åˆ†"ã€"è¯„æµ‹"æˆ–å…·ä½“æ•°å­—ï¼Œä¸å¼ºåˆ¶
    'bench1': [],
    'bench2': [],
    'cost': ['æˆæœ¬', 'æ€§ä»·æ¯”', 'ä»·æ ¼', 'ç¾å…ƒ', 'å…è´¹'],
    'price': ['ä»·æ ¼', 'è´µ', 'æˆæœ¬', 'è´¨é‡'],
    'agent': ['agent', 'æ™ºèƒ½ä½“', 'ä»»åŠ¡'],
    'pony': ['pony', 'alpha', 'ç¥ç§˜', 'æµ‹è¯•ç‰ˆ'],
    'pony1': ['pony', 'alpha', 'ç¥ç§˜', 'æµ‹è¯•ç‰ˆ'],
    'pony2': ['pony', 'alpha', 'ç¬¬ä¸€', 'æ’è¡Œ'],
    'b2b': ['b2b', 'b2c', 'å•†ä¸šåŒ–'],
    'music': ['music', 'éŸ³ä¹', 'éŸ³é¢‘'],
    'multi': [],  # multi å¤ªé€šç”¨
    'multi1': [],
    'multi2': [],
    'arch': ['æ¶æ„', 'å‚æ•°', 'æ³¨æ„åŠ›', 'ç¨€ç–'],
    'terminal': [],  # terminal åªæ˜¯è¯„æµ‹åï¼Œè¯­éŸ³å¯èƒ½æ¢è¯´æ³•
    'think': ['thinking', 'æ¨ç†', 'èƒ½åŠ›'],
    'future': ['æŒ‡æ—¥å¯å¾…', 'å³å°†', 'è“„åŠ¿', 'å¾…å‘'],
    'landscape': ['ç™¾èŠ±é½æ”¾', 'æ ¼å±€', 'ä¸€å®¶ç‹¬å¤§'],
    'budget': ['åœºæ™¯', 'é¢„ç®—', 'é€‰', 'å–å†³'],
    'cta': ['å…³æ³¨', 'ä¸‹æœŸ', 'å†è§'],
    'opening': ['æ˜¥èŠ‚', 'ç‚¸åœº', '2026'],
    'intro': [],  # intro å¤ªé€šç”¨ï¼Œä¸å¼ºåˆ¶æ£€æŸ¥
    'sum': [],    # sum/summary å¤ªé€šç”¨ï¼Œä¸å¼ºåˆ¶æ£€æŸ¥ï¼ˆä½†ä¸‹é¢ä¼šæ£€æŸ¥æ¨¡å‹åï¼‰
    'core': [],   # core å¤ªé€šç”¨
    'full': [],   # full å¤ªé€šç”¨
    'top': [],
    'btm': [],
    'creative': [],
    'models': [],
    'vs': [],
    'title': [],
}


def extract_keywords_from_filename(filename):
    """ä»æ–‡ä»¶åæå–å…³é”®è¯"""
    name = Path(filename).stem.lower()
    # å»æ‰åºå·å‰ç¼€ (01_, 02_ ç­‰)
    name = re.sub(r'^\d+_', '', name)
    # æŒ‰ _ åˆ†å‰²
    parts = name.split('_')
    return parts


def check_semantic_match(filename, speech_text):
    """
    æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶åæš—ç¤ºçš„å†…å®¹æ˜¯å¦å’Œè¯­éŸ³æ–‡å­—åŒ¹é…
    
    ç­–ç•¥ï¼š
    - æ¨¡å‹åå…³é”®è¯ï¼ˆds/glm/opus/codex/kimi/qwen/mmï¼‰åªåœ¨æ€»ç»“æ®µï¼ˆæ–‡ä»¶åå« sum_ï¼‰å¼ºåˆ¶æ£€æŸ¥
      å› ä¸ºæ­£æ–‡æ®µè½é‡Œæ¨¡å‹ååªåœ¨å¼€å¤´æä¸€æ¬¡ï¼Œåç»­è¯„æµ‹ç»†èŠ‚ä¸ä¼šé‡å¤æ¨¡å‹å
    - åŠŸèƒ½/æ¦‚å¿µå…³é”®è¯ï¼ˆswarm/cost/price/landscape/cta ç­‰ï¼‰å§‹ç»ˆæ£€æŸ¥
    
    è¿”å›: (is_ok, reason)
    """
    if not speech_text:
        return True, ""
    
    parts = extract_keywords_from_filename(filename)
    speech_lower = speech_text.lower()
    
    # åˆ¤æ–­æ˜¯å¦æ˜¯æ€»ç»“æ®µï¼ˆå»æ‰åºå·åä»¥ sum_ å¼€å¤´ï¼Œå¦‚ 37_sum_ds.pngï¼‰
    name_no_num = re.sub(r'^\d+_', '', Path(filename).stem.lower())
    is_summary = name_no_num.startswith('sum_')
    
    # æ¨¡å‹åå…³é”®è¯é›†åˆ
    MODEL_KEYS = {'ds', 'deepseek', 'glm', 'opus', 'claude', 'codex', 'gpt', 'kimi', 'qwen', 'minimax', 'mm'}
    
    mismatches = []
    for part in parts:
        if part in KEYWORD_MAP:
            expected_words = KEYWORD_MAP[part]
            if not expected_words:
                continue  # è·³è¿‡ä¸å¼ºåˆ¶æ£€æŸ¥çš„é€šç”¨è¯
            
            # æ¨¡å‹åå…³é”®è¯ï¼šåªåœ¨æ€»ç»“æ®µå¼ºåˆ¶æ£€æŸ¥
            if part in MODEL_KEYS and not is_summary:
                continue
            
            # æ£€æŸ¥è¯­éŸ³ä¸­æ˜¯å¦åŒ…å«è‡³å°‘ä¸€ä¸ªæœŸæœ›å…³é”®è¯
            found = any(w in speech_lower for w in expected_words)
            if not found:
                mismatches.append((part, expected_words))
    
    if mismatches:
        details = []
        for part, expected in mismatches:
            details.append(f"æ–‡ä»¶åå«'{part}'ä½†è¯­éŸ³ä¸­æ²¡æœ‰{expected}ä¸­çš„ä»»ä½•ä¸€ä¸ª")
        return False, '; '.join(details)
    
    return True, ""


def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python verify_alignment.py video_config.yaml")
        sys.exit(1)

    config_path = Path(sys.argv[1])
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)

    with open(config_path) as f:
        config = yaml.safe_load(f)

    work_dir = config_path.parent
    scenes = config.get('scenes', [])
    if not scenes:
        print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰ scenes")
        sys.exit(1)

    errors = []
    warnings = []

    # â”€â”€ æ”¶é›†æ‰€æœ‰å›¾ç‰‡å’Œ duration â”€â”€
    images = []
    durations = []
    audio_files = []

    for si, scene in enumerate(scenes):
        audio_path = work_dir / scene['audio']
        if not audio_path.exists():
            errors.append(f"éŸ³é¢‘ä¸å­˜åœ¨: {audio_path}")
        audio_files.append(audio_path)

        if 'images' not in scene:
            errors.append(f"åœºæ™¯ {si+1} ç¼ºå°‘ images åˆ—è¡¨")
            continue

        for img_cfg in scene['images']:
            img_path = work_dir / img_cfg['file']
            if not img_path.exists():
                errors.append(f"å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")

            d = img_cfg.get('duration')
            if d is None:
                errors.append(f"âŒ {img_cfg['file']} ç¼ºå°‘ durationï¼å¿…é¡»ä» narration.json ç²¾ç¡®è®¡ç®—ï¼")
                durations.append(0)
            else:
                try:
                    d = float(d)
                except (ValueError, TypeError):
                    errors.append(f"âŒ {img_cfg['file']} çš„ duration='{d}' ä¸æ˜¯æ•°å­—ï¼å¿…é¡»å¡«å†™ç²¾ç¡®çš„ç§’æ•°ï¼")
                    durations.append(0)
                    continue
                durations.append(d)
                if d <= 0:
                    errors.append(f"âŒ {img_cfg['file']} duration={d}ï¼Œä¸èƒ½ â‰¤ 0")
                elif d < 1.0:
                    warnings.append(f"âš  {img_cfg['file']} duration={d:.1f}sï¼Œå¤ªçŸ­ï¼ˆ<1sï¼‰")
                elif d > 7.0:
                    warnings.append(f"âš  {img_cfg['file']} duration={d:.1f}sï¼Œè¶…è¿‡7ç§’ï¼Œå»ºè®®æ‹†åˆ†")

            images.append(img_cfg['file'])

    # â”€â”€ éŸ³é¢‘æ€»æ—¶é•¿ â”€â”€
    total_audio = 0
    for af in audio_files:
        if af.exists():
            total_audio += get_audio_duration(af)

    total_image = sum(durations)
    diff = abs(total_image - total_audio)

    if diff > 1.0:
        errors.append(f"âŒ å›¾ç‰‡æ€»æ—¶é•¿({total_image:.1f}s) vs éŸ³é¢‘æ€»æ—¶é•¿({total_audio:.1f}s)ï¼Œå·®å€¼ {diff:.1f}s è¶…è¿‡ 1sï¼")
    elif diff > 0.5:
        warnings.append(f"âš  å›¾ç‰‡æ€»æ—¶é•¿({total_image:.1f}s) vs éŸ³é¢‘æ€»æ—¶é•¿({total_audio:.1f}s)ï¼Œå·®å€¼ {diff:.1f}s")

    # â”€â”€ åŠ è½½ narration.json åšè¯­ä¹‰å¯¹ç…§ â”€â”€
    timestamps = None
    if audio_files:
        timestamps = load_narration_timestamps(work_dir, audio_files[0])

    # â”€â”€ è¾“å‡ºå¯¹ç…§è¡¨ + è¯­ä¹‰æ ¡éªŒ â”€â”€
    print("\n" + "=" * 80)
    print("ğŸ“‹ å›¾æ–‡è¯­éŸ³å¯¹é½æ ¡éªŒæŠ¥å‘Š")
    print("=" * 80)

    print(f"\n{'åºå·':<4} {'å›¾ç‰‡æ–‡ä»¶':<28} {'æ—¶é•¿':>5}  {'è¯­ä¹‰':>3}  å¯¹åº”è¯­éŸ³å†…å®¹")
    print("-" * 80)

    semantic_errors = []
    cum_time = 0
    for i, (img, dur) in enumerate(zip(images, durations)):
        # åŒ¹é… narration.json ä¸­å¯¹åº”çš„å¥å­
        matched_text = ""
        if timestamps:
            start_t = cum_time
            end_t = cum_time + dur
            matched_sentences = []
            for ts in timestamps:
                if ts['end'] > start_t + 0.1 and ts['start'] < end_t - 0.1:
                    matched_sentences.append(ts['text'])
            if matched_sentences:
                matched_text = ' '.join(matched_sentences)

        # è¯­ä¹‰æ ¡éªŒ
        display_text = matched_text[:45] + "..." if len(matched_text) > 45 else matched_text
        sem_ok, sem_reason = check_semantic_match(img, matched_text)
        sem_flag = "âœ…" if sem_ok else "âŒ"
        
        if not sem_ok:
            semantic_errors.append((i + 1, img, matched_text[:60], sem_reason))

        print(f" {i+1:<3} {img:<28} {dur:>4.1f}s  {sem_flag}  {display_text}")
        cum_time += dur

    print("-" * 80)
    print(f" {'åˆè®¡':<33} {total_image:>4.1f}s")
    print(f" {'éŸ³é¢‘æ€»æ—¶é•¿':<33} {total_audio:>4.1f}s")
    print(f" {'å·®å€¼':<33} {diff:>4.1f}s")

    # â”€â”€ è¯­ä¹‰é”™è¯¯è¯¦æƒ… â”€â”€
    if semantic_errors:
        print(f"\nğŸ” è¯­ä¹‰ä¸åŒ¹é… ({len(semantic_errors)}):")
        for idx, img, text, reason in semantic_errors:
            print(f"  ç¬¬{idx}å¼  {img}")
            print(f"    è¯­éŸ³: {text}")
            print(f"    é—®é¢˜: {reason}")
        errors.append(f"âŒ {len(semantic_errors)} å¼ å›¾ç‰‡çš„æ–‡ä»¶åä¸è¯­éŸ³å†…å®¹è¯­ä¹‰ä¸åŒ¹é…ï¼å›¾ç‰‡ç”»çš„å†…å®¹å’Œè¯­éŸ³è¯´çš„å†…å®¹å¯¹ä¸ä¸Šï¼")

    # â”€â”€ è¾“å‡ºç»“æœ â”€â”€
    if warnings:
        print(f"\nâš  è­¦å‘Š ({len(warnings)}):")
        for w in warnings:
            print(f"  {w}")

    if errors:
        print(f"\nâŒ é”™è¯¯ ({len(errors)}):")
        for e in errors:
            print(f"  {e}")
        print(f"\nâ›” æ ¡éªŒå¤±è´¥ï¼è¯·ä¿®å¤ä»¥ä¸Šé—®é¢˜åå†åˆæˆè§†é¢‘ã€‚")
        print(f"   ç¦æ­¢è·³è¿‡æ ¡éªŒç›´æ¥åˆæˆï¼")
        sys.exit(1)
    else:
        print(f"\nâœ… æ ¡éªŒé€šè¿‡ï¼å›¾æ–‡è¯­éŸ³å¯¹é½æ­£ç¡®ï¼Œå¯ä»¥åˆæˆè§†é¢‘ã€‚")
        sys.exit(0)


if __name__ == "__main__":
    main()
